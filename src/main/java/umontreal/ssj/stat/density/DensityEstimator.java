
package umontreal.ssj.stat.density;

import java.util.ArrayList;

import umontreal.ssj.mcqmctools.MonteCarloModelDensityKnown;

/**
 * This abstract class implements a univariate density estimator over a finite
 * interval \f$[a,b]\f$. The density is constructed from a set of \f$n\f$
 * observations. Some of these observations can lie outside the interval
 * \f$[a,b]\f$.
 * 
 * The density can be evaluated at a single point \f$x\f$ or on a grid of
 * evaluation points.
 * 
 * Furthermore, this class implements basic routines for the computation of the
 * integrated variance (IV) as well as for calculating basic error measures,
 * such as the integrated square bias (ISB) and the mean integrated square error
 * (MISE) in case the true density is known.
 */
public abstract class DensityEstimator {

	double a;
	/**<left boundary of the interval over which we want to estimate */
	double b;

	/**<right boundary of the interval over which we want to estimate */

	/**
	 * Sets the interval @f$[a,b]@f$ over which we estimate.
	 * 
	 * @param a
	 *            left boundary of the interval.
	 * @param b
	 *            right boundary of the interval.
	 */
	public void setRange(double a, double b) {
		this.a = a;
		this.b = b;
	}

	/**
	 * Constructs the estimator from the data points in vector \a data.
	 * 
	 * @param data
	 *            the data points.
	 */
	public abstract void constructDensity(double[] data);

	/**
	 * Returns the value of the estimator evaluated at point \a x.
	 * 
	 * @param x
	 *            the point at which the density is to be evaluated.
	 * @return the value of the estimated density at x.
	 */
	public abstract double evalDensity(double x);

	/**
	 * Returns in array \a density the value of the estimator at the evaluation
	 * points in \a evalPoints. These two arrays must have the same size.
	 * 
	 * By default, it calls {@link #evalDensity(double)} for each element of \a
	 * evalpoints.
	 * 
	 * @param evalPoints
	 *            the evaluation points
	 * @param density
	 *            values of the density at these points
	 */
	public void evalDensity(double[] evalPoints, double[] density) {
		for (int i = 0; i < evalPoints.length; i++)
			density[i] = evalDensity(evalPoints[i]);
	}

	/**
	 * Gives the left boundary {@link #a} of the interval over which we estimate.
	 * 
	 * @return the left boundary of the interval
	 */
	public double geta() {
		return a;
	}

	/**
	 * Gives the right boundary {@link #b} of the interval over which we estimate.
	 * 
	 * @return the right boundary of the interval
	 */
	public double getb() {
		return b;
	}

	/**
	 * Gives a short description of the estimator.
	 * 
	 * @return a short description.
	 */
	public abstract String toString();

	/**
	 * This method estimates the density and computes the empirical IV based on
	 * \f$m\f$ independently generated simulations stored in \a data. This is done
	 * by numerically integrating the variance with integration nodes \a evalPoints
	 * over the interval \f$[a,b]\f$ on which the density estimator is defined.
	 * 
	 * 
	 * @param data
	 *            matrix in which the realizations of the model are stored.
	 * @param evalPoints
	 *            the integration nodes.
	 * @return the empirical IV
	 */
	public double computeDensityIV(double[][] data, double[] evalPoints) {
		int m = data.length;
		int numEvalPoints = evalPoints.length;

		double x, y;
		// TO DO:
		// If the density estimator is a histogram, here we may reset numEvalPoints to
		// the number of bins of the histogram.
		// int numEvalPoints = evalPoints.length();
		double estimDens[] = new double[numEvalPoints]; // Value of the density at those points
		double meanDens[] = new double[numEvalPoints]; // Average value over the rep replicates
		double varDens[] = new double[numEvalPoints]; // Variance at each evaluation point
		// Arrays.fill(meanDens, 0.0);
		// Arrays.fill(varDens, 0.0);
		for (int rep = 0; rep < m; rep++) {
			// Estimate the density for this rep and evaluate it at the evaluation points
			constructDensity(data[rep]);
			evalDensity(evalPoints, estimDens);
			// Update the empirical mean and sum of squares of centered observations at each
			// evaluation point.
			for (int j = 0; j < numEvalPoints; j++) {
				x = estimDens[j];
				y = x - meanDens[j];
				meanDens[j] += y / (double) (rep + 1);
				varDens[j] += y * (x - meanDens[j]);
			}
		}
		double sumVar = 0.0;
		for (int i = 0; i < numEvalPoints; ++i)
			sumVar += varDens[i];
		return sumVar * (b - a) / (double) (numEvalPoints * (m - 1)); // Empirical integrated variance.
	}

	/**
	 * Same as {@link #computeDensityIV(double[][], double[])} but now the
	 * evaluation points are taken as \a numEvalPoints equidistant points over
	 * \f$[a,b]\f$ generated by {@link #equidistantPoints(int)}.
	 * 
	 * @param data
	 *            matrix in which the realizations of the model are stored.
	 * @param numEvalPoints
	 *            the number of evaluation points.
	 * @return the empirical IV.
	 */
	public double computeDensityIV(double[][] data, int numEvalPoints) {
		return computeDensityIV(data, getEquidistantPoints(numEvalPoints));
	}

	/**
	 * For a \ref MonteCarloModelDensityKnown this method estimates the density and
	 * computes the ISB based on \f$m\f$ independently generated simulations stored
	 * in \a data. This is done by numerically integrating the squared bias with
	 * integration nodes \a evalPoints over the interval on which the density
	 * estimator is defined.
	 * 
	 * 
	 * This is particularly useful for testing the density estimator with a toy
	 * model.
	 * 
	 * @param model
	 *            the underlying model.
	 * @param data
	 *            matrix in which the realizations of the model are stored.
	 * @param evalPoints
	 *            the integration nodes.
	 * @return the empirical ISB
	 */
	public double computeDensityISB(MonteCarloModelDensityKnown model, double[][] data, double[] evalPoints) {

		int numEvalPoints = evalPoints.length;
		int m = data.length;

		double meanDens[] = new double[numEvalPoints];
		double sqBiasDens[] = new double[numEvalPoints]; // squared bias

		double estimDens[] = new double[numEvalPoints]; // Value of the density at evalPoints

		double x, y, z;

		for (int rep = 0; rep < m; rep++) {
			// Estimate the density and evaluate it at evalPoints
			constructDensity(data[rep]);
			evalDensity(evalPoints, estimDens);

			// Update the empirical mean and sum of squares of centered
			// observations at each evaluation point.
			for (int j = 0; j < numEvalPoints; j++) {
				x = estimDens[j];
				y = x - meanDens[j];
				meanDens[j] += y / (double) (rep + 1);
			}

		}

		for (int j = 0; j < numEvalPoints; j++) {
			z = (meanDens[j] - model.density(evalPoints[j]));
			sqBiasDens[j] = z * z;
		}

		double isb = 0.0;
		for (int i = 0; i < numEvalPoints; ++i)
			isb += sqBiasDens[i];

		return isb * (b - a) / ((double) numEvalPoints);

	}

	/**
	 * Same as
	 * {@link #computeDensityISB(MonteCarloModelDensityKnown, double[][], double[])}
	 * but using \a numEvalPoints equidistant evaluation points over @f$[a,b]@f$
	 * generated by {@link #equidistantPoints(int)}.
	 * 
	 * @param model
	 *            the underlying model.
	 * @param data
	 *            matrix in which the realizations of the model are stored.
	 * @param numEvalPoints
	 *            the number of equidistant integration nodes.
	 * @return the empirical ISB
	 */
	public double computeDensityISB(MonteCarloModelDensityKnown model, double[][] data, int numEvalPoints) {
		return computeDensityISB(model, data, getEquidistantPoints(numEvalPoints));
	}

	/**
	 * For a \ref MonteCarloModelDensityKnown this method estimates the density and
	 * computes the MISE based on \f$m\f$ independently generated simulations stored
	 * in \a data. This is done by numerically integrating the mean square error
	 * with integration nodes \a evalPoints over the interval on which the density
	 * estimator is defined.
	 * 
	 * 
	 * This is particularly useful for testing the density estimator with a toy
	 * model.
	 * 
	 * @param model
	 *            the underlying model.
	 * @param data
	 *            matrix in which the realizations of the model are stored.
	 * @param evalPoints
	 *            the integration nodes.
	 * @return the empirical MISE
	 */

	public double computeDensityMISE(MonteCarloModelDensityKnown model, double[][] data, double[] evalPoints) {

		int m = data.length;
		int numEvalPoints = evalPoints.length;

		double estimDens[] = new double[numEvalPoints]; // Value of the density
														// at evalPoints
		double mseDens[] = new double[numEvalPoints]; // mse at evalPoints

		double y;
		for (int rep = 0; rep < m; rep++) {
			// Estimate the density and evaluate it at eval points
			constructDensity(data[rep]);
			evalDensity(evalPoints, estimDens);

			for (int j = 0; j < numEvalPoints; j++) {
				y = estimDens[j] - model.density(evalPoints[j]); // model.density(x);
				mseDens[j] += y * y;
			}
		}

		double sumMISE = 0.0;
		for (int i = 0; i < numEvalPoints; ++i)
			sumMISE += mseDens[i];
		double fact = (b - a) / ((double) (numEvalPoints * m));
		return sumMISE * fact;
	}

	/**
	 * Same as
	 * {@link #computeDensityMISE(MonteCarloModelDensityKnown, double[][], double[])}
	 * but using \a numEvalPoints equidistant evaluation points over \f$[a,b]\f$
	 * generated by {@link #equidistantPoints(int)}.
	 * 
	 * @param model
	 *            the underlying model.
	 * @param data
	 *            matrix in which the realizations of the model are stored.
	 * @param numEvalPoints
	 *            the number of equidistant integration nodes.
	 * @return the empirical MISE
	 */
	public double computeDensityMISE(MonteCarloModelDensityKnown model, double[][] data, int numEvalPoints) {
		return computeDensityMISE(model, data, getEquidistantPoints(numEvalPoints));
	}

	/**
	 * Computes all traits for the density estimator that are specified in the list
	 * \a traitList. The density estimator itself is constructed from the
	 * observations in \a data and the evaluation points to compute the traits are
	 * given in \a evalPoints. Possible choices of traits are "isb", "iv", and
	 * "mise", with deviations due to letter-capitalization considered.
	 * 
	 * Since this method takes a \a model of type \ref MonteCarloModelDensityKnown,
	 * all the traits are computed empirically instead of merely estimated. This
	 * makes it particularly useful for testing estimators with toy models.
	 * 
	 * If \a traitsList contains only 1 element, then this method calls the usual
	 * method to compute the respective trait. Otherwise, it computes the traits in
	 * parallel. This leads to
	 * 
	 * The computed traits are returned in an array in the same order as they appear
	 * in \a traitsList.
	 *
	 * @param traitsList
	 *            the traits which shall be computed.
	 * 
	 * @param model
	 *            the model from which the observations were generated.
	 * @param data
	 *            matrix containing the observations of \f$m\f$ independent
	 *            repetitions.
	 * @param evalPoints
	 *            the points at which the density estimator is evaluated to compute
	 *            the trait.
	 * @return the values of the specified traits.
	 */
	// TODO:choose better name!
	public double[] computeDensityTraits(ArrayList<String> traitsList, MonteCarloModelDensityKnown model,
			double[][] data, double[] evalPoints) {
		int t = traitsList.size();
		double[] traitsVals = new double[t];
		String traitName;
		// if t=1 we can resort to the standard methods
		if (t == 1) {
			traitName = traitsList.get(0).toLowerCase();
			switch (traitName.toLowerCase()) {
			case "iv":
				traitsVals[0] = computeDensityIV(data, evalPoints);
				break;
			case "isb":
				traitsVals[0] = computeDensityISB(model, data, evalPoints);
				break;
			case "mise":
				traitsVals[0] = computeDensityISB(model, data, evalPoints);
			default:
				System.out.println("The trait " + traitName
						+ " cannot be interpreted. Supported traits are 'isb', 'iv', and 'mise'.");
			}
			return traitsVals;
		}

		// if t>1 we compute everything in parallel. This saves time
		double x, y, z;
		double dens;
		int numEvalPoints = evalPoints.length;
		int m = data.length;

		double estimDens[] = new double[numEvalPoints]; // Value of the density
														// at those points
		double meanDens[] = new double[numEvalPoints]; // Average value over rep
														// replicates
		double varDens[] = new double[numEvalPoints]; // Variance at each
														// evaluation point
		double mseDens[] = new double[numEvalPoints]; // MSE at each evaluation
														// point

		for (int rep = 0; rep < m; rep++) {
			// Estimate the density and evaluate it at evalPoints
			constructDensity(data[rep]);
			evalDensity(evalPoints, estimDens);

			// Update the empirical mean, sum of squares, and mse of
			// observations at each evaluation point.
			for (int j = 0; j < numEvalPoints; j++) {
				x = estimDens[j];
				y = x - meanDens[j];
				dens = model.density(evalPoints[j]);
				z = x - dens;

				meanDens[j] += y / (double) (rep + 1);
				varDens[j] += y * (x - meanDens[j]);
				mseDens[j] += z * z;
			}

		}

		double iv = 0.0;
		double mise = 0.0;
		// double isb = 0.0;
		for (int i = 0; i < numEvalPoints; ++i) {
			iv += varDens[i];
			mise += mseDens[i];
			// isb += biasDens[i];
		}

		double fact = (b - a) / ((double) (numEvalPoints * (m - 1.0)));
		iv *= fact;
		mise *= (b - a) / ((double) (numEvalPoints * m));

		for (int s = 0; s < t; s++) {
			traitName = traitsList.get(s).toLowerCase();
			switch (traitName.toLowerCase()) {
			case "iv":
				traitsVals[s] = iv;
				break;
			case "isb":
				traitsVals[s] = mise - iv;
				break;
			case "mise":
				traitsVals[s] = mise;
			default:
				System.out.println("The trait " + traitName
						+ " cannot be interpreted. Supported traits are 'isb', 'iv', and 'mise'.");
			}
		}

		return traitsVals;
	}

	/**
	 * Same as
	 * {@link #computeDensityTraits(ArrayList, MonteCarloModelDensityKnown, double[][], double[])}
	 * but here, the evaluation points for computing the traits are \a numEvalPoints
	 * equidistant points generated by {@link #equidistantPoints(int)}.
	 * 
	 * @param traitsList
	 *            the traits which shall be computed.
	 * 
	 * @param model
	 *            the model from which the observations were generated.
	 * @param data
	 *            matrix containing the observations of \f$m\f$ independent
	 *            repetitions.
	 * @param numEvalPoints
	 *            the number of equidistant points at which the density estimator is
	 *            evaluated to compute the trait.
	 * @return the values of the specified traits.
	 */
	public double[] computeDensityTraits(ArrayList<String> traitsList, MonteCarloModelDensityKnown model,
			double[][] data, int numEvalPoints) {
		return computeDensityTraits(traitsList, model, data, getEquidistantPoints(numEvalPoints));
	}

	/**
	 * Generates \a numPoints equidistant points over \f$[a,b]\f$ by fixing the
	 * distance between two points as \f$\delta = (b-a)/k\f$
	 * and set the first point as \f$a + \delta/2\f$.
	 * 
	 * @param k
	 *            the number of points to be returned.
	 * @return an array of equidistant points over \f$[a,b]\f$.
	 */
	protected double[] getEquidistantPoints(int k) {
		double evalPoints[] = new double[k];
		double delta = (b - a) / (k);
		for (int j = 0; j < k; j++)
			evalPoints[j] = a + delta * (0.5 + j);

		return evalPoints;
	}

	/**
	 * Computes the mean and the standard deviation of the observations of @f$m@f$
	 * simulations given in \a data.
	 * 
	 * @param data
	 *            the observations.
	 * @return the mean and standard deviation.
	 */
	// TODO: This should go somewhere else.
	public static double[] estimateMeanAndStdDeviation(double[][] data) {
		double[] result = new double[2];
		int m = data.length;
		int n = data[0].length;
		double stdDeviation = 0.0;
		double x, y;
		double meanSum = 0.0;
		for (int r = 0; r < m; r++) {

			double mean = 0.0;
			double var = 0.0;
			for (int i = 0; i < n; i++) {
				x = data[r][i];
				y = x - mean;
				mean += y / ((double) (i + 1.0));
				var += y * (x - mean);
			}
			stdDeviation += Math.sqrt(var / ((double) n - 1.0));
			meanSum += mean;
		}
		result[0] = meanSum / (double) m;
		result[1] = stdDeviation / (double) m;
		return result;
	}

	/**
	 * Computes the Coefficient of determination \f$R^2\f$ of the observed data \a
	 * data and the estimated data \a dataEstimated.
	 * 
	 * For observed data \f$y=(y_1,y_2,\dots,y_n)\f$ and estimated data \f$
	 * f=(f_1,f_2,\dots,f_n)\f$ this is defined as \f[ R^2 = 1 -
	 * \frac{\textrm{SS}_{\text{res}}}{\textrm{SS}_{\text{tot}}}, \f] where \f$
	 * \textrm{SS}_{\text{res}} \f$ denotes the sum of squares of the residuals \f[
	 * \textrm{SS}_{\text{res}} = \sum_{i=1}^n (f_i - y_i)^2 \f] and where
	 * \f$\textrm{SS}_{\text{tot}}\f$ is the total sum of squares \f[
	 * \textrm{SS}_{\text{tot}} = \sum_{i=1}^n (y_i - \bar{y})^2. \f] The closer this
	 * quantity is to one, the better the approximation of \f$y\f$ by \f$f\f$.
	 * 
	 * @param data
	 *            the observed data
	 * @param dataEstimated
	 *            the estimated data
	 * @return the Coefficient of determination \f$R^2\f$
	 */
	// TODO: should probably be put somewhere else.
	public static double coefficientOfDetermination(double[] data, double[] dataEstimated) {
		int i;
		int max = data.length;
		double maxInv = 1.0 / (double) max;
		double dataMean = 0.0;
		double SSres = 0.0;
		double SStot = 0.0;
		for (i = 0; i < max; i++)
			dataMean += data[i];
		dataMean *= maxInv;
		for (i = 0; i < max; i++) {
			SSres += (data[i] - dataEstimated[i]) * (data[i] - dataEstimated[i]);
			SStot += (data[i] - dataMean) * (data[i] - dataMean);
		}
		return 1.0 - SSres / SStot;
	}
}
